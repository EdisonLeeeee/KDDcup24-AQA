{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26dba780-56e3-409d-b86c-23875d55b97b",
   "metadata": {},
   "source": [
    "+ results: 存放最终预测结果文件夹\n",
    "+ data: 赛题数据和其他数据文件夹\n",
    "+ models: huggingface模型权重文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1e82af7-70a4-4f9e-a7ef-24cb665eac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p results\n",
    "!mkdir -p data\n",
    "!mkdidr -p models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ee12f63-9b72-4d10-8218-6216b86455fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import faiss\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def read_json(data_path: str) -> dict:\n",
    "    with open(data_path, \"r\", encoding=\"utf-8\") as fh:\n",
    "        return json.load(fh)\n",
    "        \n",
    "def read_txt(data_path: str) -> dict:\n",
    "    samples = []\n",
    "    with open(data_path, \"r\", encoding=\"utf-8\") as fh:\n",
    "        for line in fh:\n",
    "            samples.append(json.loads(line))\n",
    "    return samples\n",
    "\n",
    "def write_txt(samples, data_path: str) -> dict:\n",
    "    with open(data_path, \"w\", encoding=\"utf-8\") as fh:\n",
    "        for sample in samples:\n",
    "            fh.writelines(sample+'\\n')\n",
    "            \n",
    "def load_jsonl(file):\n",
    "    samples = []\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as fh:\n",
    "        for i, line in enumerate(fh):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            sample = json.loads(line)\n",
    "            samples.append(sample)   \n",
    "    return samples\n",
    "    \n",
    "def head(data, n=5):\n",
    "    keys = np.random.choice(list(data.keys()), n)\n",
    "    for k in keys:\n",
    "        print(data[k].keys())\n",
    "        print(data[k])\n",
    "        print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f44f2ce-25c1-4c43-aa49-877d18d08bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_json('data/AQA/AQA-test-public/pid_to_title_abs_update_filter.json')\n",
    "train_data = read_txt('data/AQA/qa_train.txt')\n",
    "val_data = read_txt('data/AQA/qa_valid_wo_ans.txt')\n",
    "test_data = read_txt('data/AQA/AQA-test-public/qa_test_wo_ans_new.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61357212-2953-475a-b8cc-6d06e4e367e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50743aeb3c2a425ea818ce756815b00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#parameters: 7851.016192M\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model_name = 'NV-Embed-v1' #\n",
    "model_path = f'models/{model_name}'\n",
    "config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)\n",
    "config.text_config._name_or_path = model_path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(model_path, config=config, \n",
    "                              trust_remote_code=True, torch_dtype=torch.float16).to(device)\n",
    "model.eval()\n",
    "print(f'#parameters: {sum([p.numel() for p in model.parameters()])/1e6}M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff4d85e-627d-49d8-adb8-91768cc682e5",
   "metadata": {},
   "source": [
    "# 使用额外的DBLP数据库提取关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3429f25a-5f0e-4fa5-ba9d-29703e8bcc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 466387/466387 [00:00<00:00, 789858.09it/s]\n"
     ]
    }
   ],
   "source": [
    "database = load_jsonl('data/DBLP-Citation-network-V15.json')\n",
    "\n",
    "database_dict = {} \n",
    "for d in database:\n",
    "    database_dict[d.pop('id')] = d\n",
    "    hit = []\n",
    "    \n",
    "for i in tqdm(data):\n",
    "    if i in database_dict:\n",
    "        hit.append(i)\n",
    "        data[i]['keywords'] = ','.join(database_dict[i]['keywords'])\n",
    "    else:\n",
    "        data[i]['keywords'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc82add-1729-4a09-95de-b197ac4c7ece",
   "metadata": {},
   "source": [
    "# 推理检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fba8dd-41f3-42ca-af16-cdd318f8219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "    return f'Instruct: {task_description}\\nQuery: {query}'\n",
    "    \n",
    "def get_paper_string(pid):\n",
    "    title = data[pid]['title']\n",
    "    abstract = data[pid]['abstract']\n",
    "    keywords = data[pid]['keywords']\n",
    "    \n",
    "    query = ''\n",
    "    if title is None:\n",
    "        query += f''\n",
    "    else:\n",
    "        query += f'{title}'\n",
    "        \n",
    "    if abstract is None:\n",
    "        query += f''\n",
    "    else:\n",
    "        query += f'{abstract}'   \n",
    "        \n",
    "    query += keywords\n",
    "    return query\n",
    "\n",
    "def get_question_string(d):\n",
    "    question = d['question']\n",
    "    body = d['body']\n",
    "    query = ''\n",
    "    \n",
    "    if question is None:\n",
    "        query += f''\n",
    "    else:\n",
    "        query += f'{question}'\n",
    "    if body is None:\n",
    "        query += f''\n",
    "    else:\n",
    "        query += f'{body}'\n",
    "        \n",
    "    # Each query must come with a one-sentence instruction that describes the task\n",
    "    task = 'Given a question, retrieve passages that answer the question' \n",
    "    query = get_detailed_instruct(task, query)\n",
    "    return query\n",
    "\n",
    "pids = []\n",
    "data_query = []\n",
    "for pid in tqdm(data):\n",
    "    query = get_paper_string(pid)\n",
    "    data_query.append(query)\n",
    "    pids.append(pid)\n",
    "    \n",
    "pids = np.array(pids)      \n",
    "\n",
    "val_question_query = []\n",
    "for d in tqdm(val_data):\n",
    "    query = get_question_string(d)\n",
    "    val_question_query.append(query)\n",
    "\n",
    "test_question_query = []\n",
    "for d in tqdm(test_data):\n",
    "    query = get_question_string(d)\n",
    "    test_question_query.append(query)\n",
    "    \n",
    "train_question_query = []\n",
    "train_pids = []\n",
    "for d in tqdm(train_data):\n",
    "    query = get_question_string(d)\n",
    "    for p in d['pids']:\n",
    "        train_question_query.append(query)\n",
    "        train_pids.append(p)\n",
    "train_pids = np.array(train_pids)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63927015-cca8-47b5-bea1-3c0e8410450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(token_embeddings, attention_mask):\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, dim=1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def last_token_pool(last_hidden_states, attention_mask):\n",
    "    left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "    if left_padding:\n",
    "        return last_hidden_states[:, -1]\n",
    "    else:\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "        return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_embedding(corpus, tokenizer, model, device, instruction, max_length=4096):   \n",
    "    e = model.encode(corpus, instruction=instruction, max_length=max_length)\n",
    "    e = e.float()\n",
    "    return e\n",
    "\n",
    "def generate_embedding(texts, tokenizer, model, device, instruction='', batch_size=32):\n",
    "    embedding = []\n",
    "    for batch in tqdm(\n",
    "            [\n",
    "                texts[i: i + batch_size]\n",
    "                for i in range(0, len(texts), batch_size)\n",
    "            ],\n",
    "            desc=\"Generating embedding\"\n",
    "    ):\n",
    "        e = get_embedding(batch, tokenizer, model, device, instruction)\n",
    "        embedding.append(e.cpu())\n",
    "    embedding = torch.cat(embedding)\n",
    "    return embedding\n",
    "\n",
    "def drop_dup(x, k=20):\n",
    "    d = {}\n",
    "    res = []\n",
    "    for i in x:\n",
    "        if i not in d:\n",
    "            d[i] = 1\n",
    "            res.append(i)\n",
    "            if len(res) == k:\n",
    "                return res\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326634e5-5ca6-4d4b-aa22-20dc8b014e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embedding:   0%|          | 0/233194 [00:00<?, ?it/s]/home/public_data/huggingface/modules/transformers_modules/NV-Embed-v1/modeling_nvembed.py:345: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'input_ids': torch.tensor(batch_dict.get('input_ids').to(batch_dict.get('input_ids')).long()),\n",
      "Generating embedding:   2%|▏         | 4361/233194 [09:47<10:46:49,  5.90it/s]"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "embeddings_corpus = generate_embedding(data_query, tokenizer, model, device, batch_size=batch_size)\n",
    "embeddings_train = generate_embedding(train_question_query, tokenizer, model, device, batch_size=batch_size)\n",
    "embeddings_val = generate_embedding(val_question_query, tokenizer, model, device, batch_size=batch_size)\n",
    "embeddings_test = generate_embedding(test_question_query, tokenizer, model, device, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31c5104-6422-4766-8708-2b47610dcad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(x):\n",
    "    dimension = x.shape[-1]\n",
    "    # index = faiss.IndexFlatL2(dimension)\n",
    "    index = faiss.IndexFlatIP(dimension)\n",
    "    index.add(x.float().cpu())\n",
    "    return index\n",
    "    \n",
    "def search(index, x, k=20):\n",
    "    distance, topk = index.search(x.float().cpu(), k)\n",
    "    return distance, topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364aa607-536b-4f94-b4ad-1e9066254ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for stage in ['val', 'test']:\n",
    "    print(stage)\n",
    "    if stage == 'val':\n",
    "        embedding = embeddings_val\n",
    "    else:\n",
    "        embedding = embeddings_test\n",
    "        \n",
    "    distance, topk = search(build_index(embeddings_corpus), embedding, 40)\n",
    "    topk = pids[topk]\n",
    "    \n",
    "    sorted_results = topk\n",
    "    \n",
    "    results = [drop_dup(r) for r in sorted_results]\n",
    "    for i in range(len(results)):\n",
    "        assert np.unique(results[i]).shape[0] == 20\n",
    "    \n",
    "    write_txt([','.join(r) for r in results], f'results/{stage}_result_{model_name}.txt')\n",
    "    torch.save({'distance': distance, 'topk': topk}, \n",
    "               f'results/{stage}_result_{model_name}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e867d96d-e6b2-4837-af0c-c4ebac368845",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'#parameters: {sum([p.numel() for p in model.parameters()])}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
